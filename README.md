# 딥러닝 & 강화 학습 관련 자료들.


[유사 논문 검색기](http://www.arxiv-sanity.com/top)

###Daily Check
- https://twitter.com/DeepMindAI
- https://twitter.com/demishassabis
- https://twitter.com/OpenAI 
- https://twitter.com/DeepLearningHub
- https://twitter.com/jackclarksf
- https://twitter.com/karpathy
- https://twitter.com/AdaptiveAgents
- [논문 설명]https://github.com/karpathy/paper-notes

## Deep Learning
###Algorithm
- CNN
  - GoogLe Net ( using InceptionV3 )
    - [CodeLab-Google](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/index.html?index=..%2F..%2Findex#0)
  - [실전 CNN ](http://www.slideshare.net/ssuser77ee21/convolutional-neural-network-in-practice)

- Recurrent Network
  - LSTM
    - [소개](https://brunch.co.kr/@chris-song/9)
  - RLU
  - E2E ( end to end Memory )
  - [generative-models](https://openai.com/blog/generative-models/)
  - [Hyper NetWorks-손글씨 인식 에제](http://blog.otoro.net/2016/09/28/hyper-networks/)
  
###Project
- Magenta 
  - [Google Magenta(작곡 딥러닝)](https://tensorflowkorea.wordpress.com/2016/07/11/magentas-paper-reviews/)
  - [music-art-and-machine-intelligence](https://tensorflowkorea.wordpress.com/2016/07/17/music-art-and-machine-intelligence-workshop-2016/)
  
### DataSet
- [3D Human Pose DataSet](http://domedb.perception.cs.cmu.edu/dataset.html)
- [google youtube video dataSet](https://research.googleblog.com/2016/09/announcing-youtube-8m-large-and-diverse.html)
- [google image dataSet](https://tensorflowkorea.wordpress.com/2016/10/02/open-images-dataset/)
- [KAIST_Corpus](http://semanticweb.kaist.ac.kr/home/index.php/KAIST_Corpus)
- [Datasets for Machine Learning List](https://docs.google.com/spreadsheets/d/1AQvZ7-Kg0lSZtG1wlgbIsrm90HaTZrJGQMz-uKRRlFw/edit#gid=0)  

###Posting
- [Nvidia- DL traing kit with Lecun](https://developer.nvidia.com/teaching-kits)
- [Leading the New Era of Machine Intelligence](http://numenta.com/applications/)
- [The Brain Tech to Merge Humans and AI Is Already Being Developed](http://singularityhub.com/2016/12/05/the-brain-tech-to-merge-humans-and-ai-is-already-being-developed/)
- [A top Google researcher talks about increasingly intelligent computers-jeff-dean](http://fortune.com/2016/11/26/google-artificial-intelligence-jeff-dean/)
- [Model based ML](http://mbmlbook.com/index.html)
- [Deep Learning the Stock Market](https://medium.com/@TalPerry/deep-learning-the-stock-market-df853d139e02#.pi425qopy)
- [How the brain recognizes faces](http://news.mit.edu/2016/machine-learning-system-brain-recognizes-faces-1201) 
- [Convergent Learning: Do different neural networks learn the same representations?](http://videolectures.net/iclr2016_yosinski_convergent_learning/)
- [뇌의 단기기억](http://www.dongascience.com/news/view/15092)
    - 스치고 지나간 사람의 얼굴도 뇌는 기억한다.  
단기 기억 사실도 모두 뇌에 기록된다.  
헬리콥터를 타고 시가지를 한번 돌아보고   
도시 전체의 상세한 그림을 사진을 찍은 듯이   
기억해서 그리는 서번트 기능을 이해할 수 있을 듯.  
일반인도 누구나 한번번 것을 사진을 찍듯이 뇌에 저장한다.   
단지 재생하는 스위치를 켜지 못할 뿐.  
“이번 연구는 단기기억은 휴면 상태에 있을 뿐 반복해서 상기시키지 않아도 사라지지 않는다는 사실을 밝혀낸 것”이라며 “단기기억도 얼마든지 재생이 가능하다는 뜻”  
- [얀쿤 교수님 !!! - 6가지 기초 AI](https://code.facebook.com/posts/384869298519962/artificial-intelligence-revealed/)
- [CNN 기초-조대협](http://bcho.tistory.com/1149)
- [Plug & Play Generative Networks: Conditional Iterative Generation of Images in Latent Space](http://www.evolvingai.org/ppgn)
    - I am very excited to announce our latest paper. It introduces “Plug & Play Generative Networks,” which we believe represents a state of the art generative model* and deep visualization method. What do you think? We’re excited to see what the community does with PPGNs! Note that the below images are synthetic images produced by deep neural networks (a form of AI).  
Nguyen A, Yosinski J, Bengio Y, Dosovitskiy A, Clune J (2016) Plug & Play Generative Networks: Conditional Iterative Generation of Images in Latent Space. arXiv 1738978 (submitted). PDF and more available here: http://www.evolvingai.org/ppgn  
Thanks to all of the wonderfully talented coauthors, especially lead author Anh Nguyen!  
With the following caveats: (1) evaluating generative models must be done qualitatively, as all quantitative approaches are riddled with problems and humans are still the best evaluators even if they are subjective and imperfect, (2) for high-resolution images (~ImageNet size) and in terms of both image quality and diversity at high-res  
- [Broca and Wernicke Are Dead – It’s Time to Rewrite the Neurobiology of Language](http://neurosciencenews.com/broca-and-wernicke-are-dead-its-time-to-rewrite-the-neurobiology-of-language/)
- [사진을 애니메이션으로 -This Algorithm Taught Itself to Animate a Still Photo- ](http://motherboard.vice.com/read/researchers-taught-a-machine-how-to-generate-the-next-frames-in-a-video)
- [당뇨성 망막병증 - 구글](https://research.googleblog.com/2016/11/deep-learning-for-detection-of-diabetic.html)
  - 오늘 소개해 드릴 논문은 "Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs" (JAMA, http://jamanetwork.com/journals/jama/fullarticle/2588763) 입니다. 
구글의 연구인데, 관련 블로그 내용은 https://research.googleblog.com/…/deep-learning-for-detecti… 입니다.
이미 지난 구글 I/O 2016에서 피차이 CEO가 구글은 인공지능을 이용해 당뇨 합병증인 당뇨성 망막병증(diabetic retinopathy)을 진단하는 기술을 개발 중이라고 발표했었습니다. 이 논문은 그 결과를 정리한 논문입니다. 뭐.. 한마디로 정리하자면 딥러닝 적용해서 의사보다 더 정확했다!!! 끝 입니다.
inception-v3 기반으로 이미지넷 기반 선학습된 모델을 사용, 당연히 batch normalization 쓰고, 하나의 네트웍에서 여러 binary prediction을 하게 학습, ealry stopping을 쓰고.. 10개의 모델을 앙상블 했음.. 등등 딥러닝을 좀 아시는 분이라면 딥러닝 기술로는 그닥 새로울 것이 없다고 보실 수 있습니다. (그만큼 그 뒤에 숨은 노하우와 노력들은 기술되지 않은 논문입니다... 개인적으로 그 뒤에 얼마나 노력을 했는지가 궁금하지만...) 말씀드렸듯이 개발 중인 기술의 실험 결과를 보이고 실험 분석을 하는데 더 집중한 논문입니다.
그런데도 불구하고 소개해 드린 것은 .. 제 입장에서 의학 용어가 어려워 귀찮았던 논문이지만 Discussion 부분은 다들 읽어봄직한 내용이였습니다.  
1/ 딥러닝을 이용하면 기존 lesion 기반 특징을 안 쓰고도 높은 성능으로 당뇨성 망막병증을 판별할 수 있었다  
2/ 그러나 좋은 데이터를 많이 가지고 있어야 한다.   
-abnormal case에 해당하는 몇만장의 데이터가 필요함 (실험에서는 60000장 정도 넣었을 때, tuning이 saturate함.)  
-Tuning and clinical validation set은 multiple grade를 가지고 있어야 함.   
3/ 뉴럴넷은 그냥 판단하고 grade만 말하는데... explicit definition of feature를 말하지 않는다.   
-판단에 좋은 특징을 학습할 뿐이지 무슨 의미인지 모른다.   
-이 것이 기존에 몰랐던 것일 수도 있고, 무시되 왔던 것일 수도 있지만.. 연구되어야 한다 아니.. 활발히 연구되고 있다.   
4/ 그럼에도 불구하고 모든 안과 검사를 대체하는 것이 아니다.   
-이 문구는 딥마인드와 구글의 모든 의료 연구의 마지막에 꼭 붙는 문구입니다.  
개인적으로 3번에서 뉴럴넷이 발견한 특징을 다시 의사 집단에서 연구해서 의미를 찾고, 그것을 다시 뉴럴넷 발전에 쓰고, 이런 선순환이 이미 진행되고 있는 것으로 보인다는게 반갑고요. 또한 이러면서도 FDA 등 다양한 집단과 논의하며 충분히 조심스럽게 접근하고 있다는 느낌입니다.
저희 나라에도 루닛, VUNO Inc., DeepBio 등 여러 스타트업이 병원가 협업을 하면서 식약청 승인등을 준비하는 것으로 압니다. 단순히 성능의 수치뿐 아니라 현실적으로 의학쪽에서도 뉴럴넷으로 발견된 결과를 받아서 발전하고, 또 그런 인사이트를 공학쪽에서도 받아서 발전하는 결과를 기대해 봅니다. (이미 그러고 있는 걸로 알지만요 ^^)

- [GRAM: Graph-based Attention Model. A better learning representation ?](https://theinformationageblog.wordpress.com/2016/11/29/gram-graph-based-attention-model-a-better-learning-representation/)
- [Long paper review of Attend, Infer, Repeat: Fast Scene Understanding with Generative Models](https://theinformationageblog.wordpress.com/2016/11/24/long-paper-review-of-attend-infer-repeat-fast-scene-understanding-with-generative-models/)
- [GAN & PixelCNN - New Paper- Korean](https://tensorflow.blog/2016/11/24/gan-pixelcnn/)
  - [PixelCNN [1601.06759] Summary-한글](https://tensorflow.blog/2016/11/29/pixelcnn-1601-06759-summary/)
- [Tensorflow and deep learning - without at PhD by Martin Görner](https://www.youtube.com/watch?v=vq2nnJ4g6N0&feature=youtu.be)
- [awesome-deep-vision](https://github.com/kjw0612/awesome-deep-vision)
- [현대적 얼굴 인식](https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78#.m0jnipu5o)
- [Bayesian Deep Learning Part II: Bridging PyMC3 and Lasagne to build a Hierarchical Neural Network](https://www.opendatascience.com/blog/bayesian-deep-learning-part-ii-bridging-pymc3-and-lasagne-to-build-a-hierarchical-neural-network/?utm_source=Open+Data+Science+Newsletter&utm_campaign=d7d409aef5-EMAIL_CAMPAIGN_2016_11_21&utm_medium=email&utm_term=0_2ea92bb125-d7d409aef5-245860601)
- [Understanding Convolutional Neural Networks for NLP](https://www.opendatascience.com/blog/understanding-convolutional-neural-networks-for-nlp/?+Data+Science+Newsletter&utm_term=0_2ea92bb125-d7d409aef5-245860601)
- [Deep Learning AI Made More Rational by MIT](https://edgylabs.com/2016/11/16/deep-learning-ai-human/)
- [Our Brains Have a Basic Algorithm That Enables Our Intelligence](http://neurosciencenews.com/brain-algorithm-intelligence-5562/)
- [NEUROSCIENCE news](http://neurosciencenews.com/neuroscience-topics/neuroscience/)
- [Urban Sound Classification](https://tensorflowkorea.wordpress.com/2016/11/06/urban-sound-classification/)
- [논문리뷰/  구글, 인공지능 기반 암호화 알고리즘 개발](http://cpuu.postype.com/post/422940/)
- [Attention and Augmented Recurrent Neural Networks](http://distill.pub/2016/augmented-rnns/?utm_content=buffer55654&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer)
- [Random synaptic feedback weights support error backpropagation for deep learning](http://www.nature.com/articles/ncomms13276)
- [deep-learning-papers-reading-roadmap]
 - [tensorflow](https://tensorflowkorea.wordpress.com/2016/10/25/deep-learning-papers-reading-roadmap/)
 - [github Page](https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap)
- [openai-infrastructure-for-deep-learning](https://openai.com/blog/infrastructure-for-deep-learning/)
- [Attention and Augmented Recurrent Neural Networks](http://distill.pub/2016/augmented-rnns/)
- [how-to-run-text-summarization-with-TF](https://medium.com/@surmenok/how-to-run-text-summarization-with-tensorflow-d4472587602d#.4cec2w7t3)
- [introduction-to-deep-learning](http://blog.algorithmia.com/introduction-to-deep-learning-2016/)
- [해커에게 전해들은 머신러닝](https://tensorflowkorea.wordpress.com/2016/10/31/%ED%95%B4%EC%BB%A4%EC%97%90%EA%B2%8C-%EC%A0%84%ED%95%B4%EB%93%A4%EC%9D%80-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/)
- [WaveNet: DeepMind’s New Model for Audio](https://tensorflowkorea.wordpress.com/2016/09/09/wavenet-deepminds-new-model-for-audio/)
- [Generating Videos with Scene Dynamics](http://web.mit.edu/vondrick/tinyvideo/)
- [Deep Learning For 이미지 분석 ](https://www.facebook.com/groups/TensorFlowKR/permalink/321214624886269/) 
- [Image Completion with Deep Learning in TensorFlow](http://bamos.github.io/2016/08/09/deep-completion/)
  - [구현](https://github.com/jazzsaxmafia/Inpainting)   
- [Face Auto Gen](https://tensorflowkorea.wordpress.com/2016/08/18/neural-facegrid-by-discgen/)
- [Google opensource new image captioning](https://tensorflowkorea.wordpress.com/2016/09/23/google-opensource-new-image-captioning-model-im2txt/)
- [ConvNet with WebGL](https://tensorflowkorea.wordpress.com/2016/08/18/convnet-with-webgl/)
- deeplearning2016_montreal
  - [Video](http://videolectures.net/deeplearning2016_montreal/)
- [AI 온라인 컨퍼런스](http://ai.withthebest.com/)
- [Deep Learing Book Study](https://tensorflowkorea.wordpress.com/2016/09/23/deep-learning-textbook-study-group/)
- [Machine Learning Top 10 Articles ](https://medium.mybridge.co/machine-learning-top-10-articles-for-the-past-month-2f3cb815ffed#.v5pj4aa7o)
- [Beyond Deep Learning – 3rd Generation Neural Nets](http://www.datasciencecentral.com/profiles/blogs/beyond-deep-learning-3rd-generation-neural-nets)
- facebook Object Recognation in Image 
  - [facebook posting](https://code.facebook.com/posts/561187904071636)
  - [tensorflowkorea Po](https://tensorflowkorea.wordpress.com/2016/08/26/facebook-open-source-image-recognition-tools/)
  
###tensorflow
- [distributed-tensorflow](https://tensorflowkorea.wordpress.com/2016/07/17/distributed-tensorflow-design-patterns-and-best-practices/)

###Lecture
- [Open Source Deep Learning Curriculum](http://www.deeplearningweekly.com/pages/open_source_deep_learning_curriculum)
- [NLP: Everyday, Analytical & Unusual Uses](http://www.allanalytics.com/document.asp?doc_id=260387)
- [ML Book- By andrew Ag](https://gallery.mailchimp.com/dc3a7ef4d750c0abfc19202a3/files/Machine_Learning_Yearning_V0.5_01.pdf)
- sung kim - https://www.youtube.com/watch?v=BS6O0zOGX4E&list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm
- CS231n: [Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/) / [Video](https://www.youtube.com/watch?v=NfnWJUyUJYU&list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC) /[강의 노트 한글](http://ishuca.tistory.com/category/CS231n)
- Kmooc :
  - 경영데이터 마이닝 : http://www.kmooc.kr/courses/course-v1:HYUk+HYUBUS3099k+2016_C1/info
  - 인공지능과 기계학습 : http://www.kmooc.kr/courses/course-v1:KAISTk+KCS470+2015_K0201/info
- [Deep Generative Models](https://portal.klewel.com/watch/webcast/deep-learning-tools-and-methods-workshop/talk/6)
- [ICML’15](http://dpkingma.com/?page_id=483)
- [Google I/O Extended Seoul 2016 - Tensorflow 101](https://www.youtube.com/watch?v=7UwAz4Jvvko)
- [Deep Learning for Computer Vision Barcelona 2016 ](http://imatge-upc.github.io/telecombcn-2016-dlcv/)
- [코세라 NLP](https://www.coursera.org/learn/natural-language-processing)
- [아카데믹 토렌트](http://academictorrents.com/)
- [
creative-applications-of-deep-learning-with-TF](https://www.kadenze.com/courses/creative-applications-of-deep-learning-with-tensorflow/info)
- [reddt- begginer wiki](https://www.reddit.com/r/LearnMachineLearning/wiki/reference)
- EXEM Seminar
  - [뇌과학으로 본 인공지능의 현주소와 미래 01](https://www.youtube.com/watch?v=efWSbITntR0)
  - [EXEM Seminar / 뇌과학으로 본 인공지능의 현주소와 미래 ](https://www.youtube.com/watch?v=48EsevSvoRw)

 
###Papers
- [Generative Shape Models: Joint Text Recognition and Segmentation with Very Little Training Data](https://arxiv.org/pdf/1611.02788.pdf)
- [Photorealistic Facial Texture Inference Using Deep Neural Networks](https://arxiv.org/abs/1612.00523v1)
  - Researcher Hao Li, Shunsuke Saito , Lingyu Wei , Koki Nagano, and Liwen Hu wanted to create super-detailed face models without the need for professional lighting or even a full photo.Face mapping at this level usually requires a series of photos in ideal lighting to make sure you get all the curves,angles, and asymmetries of the face.The researcher relied on an extensive "face database" to make smart inferences on the finer detail of the face.Neural networks create the face by filtering through a network of possible textures before scanning and then blending the pertinent facial features and skin tones.
- [SamepleRNN-ICLR2017-Gen Audio ](https://github.com/soroushmehr/sampleRNN_ICLR2017)
- [Neural Network-based Automatic Image Colorization](http://hi.cs.waseda.ac.jp/~iizuka/projects/colorization/en/)
- [Designing Neural Network Architectures using Reinforcement Learning](https://arxiv.org/abs/1611.02167)
  - 오늘 소개시켜드릴 논문은 "Designing Neural Network Architectures using Reinforcement Learning" (Under review as a conference paper at ICLR 2017, https://arxiv.org/abs/1611.02167)입니다. Media Laboratory에서 나온 논문으로.. 제목에서 아시겠지만 제한적이지만, 그동안 딥러닝을 공부하면 늘 하던 질문에 답을 던지려하는 논문입니다.  
딥러닝 관련해서 세미나에 참석해 보면 많은 분들이 던지는 질문 중 하나가 "네트웍을 어떻게 디자인하냐?"였습니다. 벤지오 교수님은.."일단 될 때까지 쌓아보세요~"라고 대답하신 걸 봤고, karpathy는 히어로가 되지 말고 많은 분들이 해 놓으신걸 가져다 쓰시는게 낫다라고도 했던거 같습니다.  
이 논문은 Reinforcement learning을 이용하여 자동적 (제한적인... 자동적)으로 neural network 구조를 디자인해 보자입니다. layer이 디자인 요소를 액션으로 그리고 validation accuracy을 reward로 하는 Q-learning을 통해 neural network 구조를 자동적으로 만들어 주는 구조입니다.  
물론.. 제약사항이 따릅니다. 일단 action이 어떻게 될지 미리 정해 줘야 하기에 layer가 어떻게 구성될지의 관한 방식은 정해져있습니다. 그래서 많은 논문에서 나왔던 창의적인 방법이 들어갈 요소가 나올 수는 없는 구조이고, 그리고 아직 최대 layer 갯수등의 제약 사항이 들어가 줘야 합니다. 그리고 뭐.. 예상하시겠지만 .. 정말 많은 모델이 실험되어야 하는 구조이죠.  
그러나 충분히 재밋는 어프로치이고, 많은 분들이 가능성은 제기했던 방식이지만 이렇게 논문으로 딱 되요!! 라고 보니 반갑습니다. 저도 아침에 잠시 짬내어 대강 훑어본 수준이라 다시 한번 읽어봐야겠네요.  
그런데.. 곧 NIPS 논문도 쏟아지겠지만, ICLR은 작은 학회임에도 재밋는 논문이 많네요. 많은 논문 중 어떤 논문이 오랄섹션에 가게될지 기대되네요.  
- [A state of the art generative model : Plug and Play Generative Networks](http://www.evolvingai.org/ppgn)
  - I am very excited to announce our latest paper. It introduces “Plug & Play Generative Networks,” which we believe represents a state of the art generative model* and deep visualization method. What do you think? We’re excited to see what the community does with PPGNs! Note that the below images are synthetic images produced by deep neural networks (a form of AI).  
Nguyen A, Yosinski J, Bengio Y, Dosovitskiy A, Clune J (2016) Plug & Play Generative Networks: Conditional Iterative Generation of Images in Latent Space. arXiv 1738978 (submitted). PDF and more available here: http://www.evolvingai.org/ppgn  
https://arxiv.org/abs/1612.00005  
Thanks to all of the wonderfully talented coauthors, especially lead author Anh Nguyen!  
With the following caveats: (1) evaluating generative models must be done qualitatively, as all quantitative approaches are riddled with problems and humans are still the best evaluators even if they are subjective and imperfect, (2) for high-resolution images (~ImageNet size) and in terms of both image quality and diversity at high-res  
- [QUASI-RECURRENT NEURAL NETWORKS]
  - [paper](https://arxiv.org/pdf/1611.01576v1.pdf)
  - [영어설명](http://metamind.io/research/new-neural-network-building-block-allows-faster-and-more-accurate-text-understanding/)
- [Deepmind-Neural Machine Translation in Linear Time](https://arxiv.org/pdf/1610.10099v1.pdf)
 - WaveNet architecture를 응용하여 구현한 것으로, 두 개의 dilated conv stack을 묶어서 linear time translation을 구현하였습니다. 응용 범위가 상당히 많을 것 같네요. sequence to sequence linear time transformation filter가 필요한 경우에 적용하면 잘 될 것 같습니다.
예를 들어, deep professional singer(일반인의 노래를 가수처럼 바꿔주는 conditional network) 같은 것도 가능할 것 같고요. :)
기존의 RNN approach보다 "긴 시간"의 정보를 손실 없이 잘 capture해 낼 수 있기에, 시계열 정보 분석에서도 탁월한 성능을 내지 않을까 추측해 봅니다
- [Twitter-Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network](https://arxiv.org/abs/1609.05158)
- [Image-to-Image Translation with Conditional Adversarial Networks-edge to photo](https://arxiv.org/pdf/1611.07004v1.pdf)
  - [Korean](https://tensorflow.blog/2016/11/24/gan-pixelcnn/)
- Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation
   - [paper](https://arxiv.org/abs/1609.08144)
     - [한국어 설명](http://photohistory.tistory.com/16745)
     - [english Desc](http://smerity.com/articles/2016/google_nmt_arch.html)
   - [여러가지 언어 한꺼번에 학습](https://arxiv.org/abs/1611.04558)
     - GNMT에 대한 또 다른 논문입니다. 구글 번역에서 지원해야 하는 언어쌍이 수백가지가 넘는데, 이걸 하나하나 학습시키려면 데이터 수도 문제고 시간이 오래 걸리겠죠.
여러 언어를 동시에 번역하도록 학습했더니 한번도 학습에 사용한 적이 없는 언어쌍에 대해서도 번역이 가능했다고 합니다.
   - [Zero-Shot Translation with Google’s Multilingual Neural Machine Translation System](https://research.googleblog.com/2016/11/zero-shot-translation-with-googles.html)
- [fast-weights-rnn](https://tensorflowkorea.wordpress.com/2016/10/25/fast-weights-rnn/)
- [Deep Feature Interpolation for Image Content Changes](https://arxiv.org/abs/1611.05507)
- [PVANET: Deep but Lightweight Neural Networks for Real-time Object Detection](https://arxiv.org/abs/1608.08021)
  - [imp](https://github.com/sanghoon/pva-faster-rcnn)
  - 오늘 AI Korea에 PVANET 논문이 소개되었습니다. 예전에 재밋게 읽었던 논문이고, 1저자이신 김계현 (Kim Kye-Hyeon)님은 Intel Korea에서 현재는 SK T-Brain에 계신 것으로 알고 있습니다. (역시 고급 인력들이 많이 계시는 SK T-Brain이네요. )
이 논문을 읽으시면서 참고하실 만한 논문을 소개시켜드릴까 합니다. 좀 오래된 논문인데, Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units (https://arxiv.org/abs/1603.05201, ICML 2016) 입니다. 유명하신 이홍락 교수님 그룹에서 나온 논문입니다. 이 논문의 핵심 아이디어는 Concatenated rectified linear unit인데, 간단히 설명드리면, conv_1 ~ 3 정도 아래 conv_layer에서 conv_layer의 값을 negate하고, 원래 값과 그 값을 연결하여 ReLU로 보낸다입니다.
이 말이 무슨 말이냐면.. 논문의 그림에서 확인하실 수 있겠지만, AlexNet과 같은 네트웍의 낮은 레이어 (conv_1~3)정도의 filter들이 서로 opposite한 filter들이 많이 존재한다는 것을 관찰하였습니다. 그래서 그런 opposite한 filter를 학습 및 계산해주는 대신 filter의 activation 값을 negation해 주고 concatenate 시켜서 넘긴다는 아이디어입니다. 그닥 많은 연산이 필요없는 negation 연산을 통해 학습이 많은 opposite한 filter들을 학습할 필요도 없고 계산할 필요도 없어집니다.
PVANET의 디자인에서 가장 눈에 띄는 건 이 Concatenated rectified linear unit와 1x1 convolution 등을 이용하여 Inception 개념을 적용한 거라고 보입니다.
아.. 얘기를 시작한 김에.. 이홍락 교수님 논문에서 발견한 특징은 낮은 레이어의 conv layer의 filter들이 서로 opposite한 경향이 크다는 것이였습니다. 그런데, 최근 Doubly Convolutional Neural Networks (NIPS 2016, https://arxiv.org/abs/1610.09716) 논문에서는 서로 translation을 하였을 경우의 correlation이 상당히 높은 filter들이 많이 존재한다는 것을 관찰하고 그 특성을 이용할 수 있는 방식으로 Double Convolution이라는 개념을 적용하여 논문을 제출하였습니다. 또한 최근 ASP Vision: Optically Computing the First Layer of Convolutional Neural Networks using Angle Sensitive Pixels (https://arxiv.org/abs/1605.03621v3)란 논문을 읽어보면 각 filter들의 Angle에 대한 논의도 보실 수 있을거 같습니다.
아무튼 -_- 논문이 소개된걸 다시 소개하러 왔다 헛소리만..
- [OpenAI-Improved Techniques for Training GANs](https://arxiv.org/pdf/1606.03498v1.pdf)
- [Video Pixel Networks](https://arxiv.org/pdf/1610.00527v1.pdf)
- A New Method to Visualize Deep Neural Networks( Deep NN  시각화 ) -  http://arxiv.org/abs/1603.02518v2
- Deep Speech 2(음성인식) - https://arxiv.org/abs/1512.02595
- [Bag of Tricks for Efficient Text Classification-CPU가 더 빠른.](https://arxiv.org/pdf/1607.01759v2.pdf)
- [Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding](https://arxiv.org/abs/1606.01847)
- [지워진 부분 그리기 Context Encoders: Feature Learning by Inpainting](http://people.eecs.berkeley.edu/~pathak/context_encoder/)
- [Layer Normalization](http://arxiv.org/pdf/1607.06450.pdf) - 배치 노말라이제이션을 변형하여 입력 데이터의 평균과 분산을 이용해 레이어 노말라이제이션을 적용
  - https://tensorflowkorea.wordpress.com/2016/07/24/layer-normalization/ 
- [Matching Networks for One Shot Learning  ](https://arxiv.org/pdf/1606.04080.pdf)
  - [정리](https://github.com/karpathy/paper-notes/blob/master/matching_networks.md)
- [학습과 에러전파를 따로-DeepMind Decoupled Neural Interfaces using Synthetic Gradients](https://arxiv.org/pdf/1608.05343.pdf) 
  - [summary](https://tensorflowkorea.wordpress.com/2016/08/22/decoupled-neural-interfaces-using-synthetic-gradients1608-05343-summary/) 
  - [Deep mind BLog](https://deepmind.com/blog#decoupled-neural-interfaces-using-synthetic-gradients)
  - [summary2](https://tensorflowkorea.wordpress.com/2016/08/31/synthetic-gradient-revisited/)
- [Densely Connected Convolutional Networks](http://arxiv.org/abs/1608.06993)
  - 오늘 소개시켜 드릴 논문은 "Densely Connected Convolutional Networks" (http://arxiv.org/abs/1608.06993)입니다.
일종의 residual network라고 볼 수 있을거 같습니다. 그런데 논문에 나온 그래도, "each layer is directly connected to every other layer in a feed-forward fashion" 모든 레이어가 앞에 나오는 모든 레이어와 직접 연결되어 있습니다. 그래서 이름이 Densely Connected Convolutional Networks (DenseNet) 입니다.
일단 설명만 들어도 복잡하고 파라미터가 많아질거 같습니다. 그러나 저자들은 이렇게 연결을 많이 해서 생기는 장점때문에 오히려 적은 레이어가 필요하여 생각하는 만큼 오버헤드도 크지 않고 오히려 효율적이라고 하고 있습니다. 그 중 가장 중점이 되는 주장은 skip-connection으로 모든 레이어에 연결되어 있어 feature의 재상용이 증가하고, 그럼으로 파라미터가 줄어든다고 합니다.
음.. 저자들의 일방적인 주장같지만 어쩌면 일리가 있습니다. Residual Networks are Exponential Ensembles of Relatively Shallow Networks(https://arxiv.org/abs/1605.06431)에 보면 어려운 task를 할 때 resinet을 이루는 Shallow Networks들의 길이가 더 길어지고 쉬운 일을 할 때 좀 짧아진다고 한듯...(기억이 가물..가물) 합니다. 그렇다면 중복이나 비효율성이 있을거고 그것을 줄이는 방법으로 한듯 합니다.
이렇게 무식해 보이지만 다 연결해서 몇 public set에서는 최고 성능을 찍었습니다. 그러고 보니 최근 이런 식의 skip connection을 늘리는 연구가 많이 진행 되었습니다.
    - AdaNet: Adaptive Structural Learning of Artificial Neural Networks (https://arxiv.org/pdf/1607.01097v1.pdf)
    - Collaborative Layer-wise Discriminative Learning in Deep Neural Networks (https://arxiv.org/pdf/1607.05440v1.pdf)
AdaNet이나 Collaborative Layer-wise Discriminative Learning 같은 경우는 skip connection을 상황에 맞게 늘리는 것으로 이해했습니다. (물론 제가 맞는지 저도 모른다는거..) 비교할만한 성능이 제시 안 되어 있어 비교는 힘들지만, deep learning이라는 점에서 무식해 보이는 densenet이 오히려 좋을 수 있을거라는 생각이 듭니다. 학습 과정에서 또 알아서 최적화를 해 버릴 수 있다는 이상한 예감이....
 
###구현 
- [Awesome Tensorflow Implementations](https://github.com/TensorFlowKR/awesome_tensorflow_implementations)
- deep-learning-for-chatbots : http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/
- [Caption Gen, slide Shaer](http://www.slideshare.net/ssuser06e0c5/a-neural-image-caption-generator)
- [Papers implemented By Tensorflow](https://github.com/LeavesBreathe/tensorflow_with_latest_papers)
- [fast waveNet 구현](https://github.com/tomlepaine/fast-wavenet)
- [ML_Practice with TensorFlow-Korean](https://github.com/proauto/ML_Practice)



###Python & tensorflow & DL FrameWork
- 조대협의 블로그
    - [텐서플로우-#1 자료형의 이해](http://bcho.tistory.com/1150)
- [tiny-dnn-deep learning framework in C++11](https://github.com/tiny-dnn/tiny-dnn)
- [수학 & 딥러닝 블로그](http://blog.theeluwin.kr/)
- [머신 러닝 배우기]
 - [aidenswmo-Korean](https://brunch.co.kr/@aidenswmo/2)
 - [Machines Can Now Recognize Something After Seeing It Once](https://www.technologyreview.com/s/602779/machines-can-now-recognize-something-after-seeing-it-once/)
- [learning tensorflow](http://learningtensorflow.com/)
  - [2](http://theeluwin.kr/)
- [intsatll tensorflow in ubuntu16](http://www.popit.kr/tensorflow-install-ubuntu16/)
- [python tutorial 5hours](https://www.youtube.com/watch?v=emY34tSKXc4)
- [python study by MS](https://mva.microsoft.com/ko/training-courses/python%EC%9D%84-%EC%82%AC%EC%9A%A9%ED%95%9C-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D-%EC%86%8C%EA%B0%9C-8360?l=CrrhO0O8_6204984382)
- [python 이해하기](http://www.slideshare.net/dahlmoon/python-20160815)
- [딥러닝을 위한 기초 수학](http://www.slideshare.net/theeluwin/ss-69596991)
- [파이썬 class 및 인스턴스 생성 이해하기](http://www.slideshare.net/dahlmoon/array-20160317?from_m_app=ios)
- [Node.js by MS](https://mva.microsoft.com/en-US/training-courses/using-nodejs-with-visual-studio-code-13920?l=nSEpCdzbB_001937557)
- [neural-networks-and-tensorflow-introduction](https://tensorflowkorea.wordpress.com/2016/08/23/dl-with-neural-networks-and-tensorflow-introduction/)
- [R에서 파이썬까지…데이터과학 학습 사이트 8곳](http://www.bloter.net/archives/237013?rccode=lvRc)
- [Open sourcing the Embedding Projector: a tool for visualizing high dimensional data]
  - [Google R&D Blog](https://research.googleblog.com/2016/12/open-sourcing-embedding-projector-tool.html?m=1)
  - [Paper](https://arxiv.org/pdf/1611.05469v1.pdf)
- [Artificial Intelligence Open Network](http://ai-on.org/projects/)
 - [github](https://github.com/AI-ON/ai-on.org)

