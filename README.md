# 딥러닝 & 강화 학습 관련 자료들.
###Python & tensorflow
- [머신 러닝 배우기]
 - [aidenswmo-Korean](https://brunch.co.kr/@aidenswmo/2)
 - [Machines Can Now Recognize Something After Seeing It Once](https://www.technologyreview.com/s/602779/machines-can-now-recognize-something-after-seeing-it-once/)
- [learning tensorflow](http://learningtensorflow.com/)
- [intsatll tensorflow in ubuntu16](http://www.popit.kr/tensorflow-install-ubuntu16/)
- [python tutorial 5hours](https://www.youtube.com/watch?v=emY34tSKXc4)
- [python study by MS](https://mva.microsoft.com/ko/training-courses/python%EC%9D%84-%EC%82%AC%EC%9A%A9%ED%95%9C-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D-%EC%86%8C%EA%B0%9C-8360?l=CrrhO0O8_6204984382)
- [python 이해하기](http://www.slideshare.net/dahlmoon/python-20160815)
- [Node.js by MS](https://mva.microsoft.com/en-US/training-courses/using-nodejs-with-visual-studio-code-13920?l=nSEpCdzbB_001937557)
- [neural-networks-and-tensorflow-introduction](https://tensorflowkorea.wordpress.com/2016/08/23/dl-with-neural-networks-and-tensorflow-introduction/)
- [R에서 파이썬까지…데이터과학 학습 사이트 8곳](http://www.bloter.net/archives/237013?rccode=lvRc)
- [Artificial Intelligence Open Network](http://ai-on.org/projects/)
 - [github](https://github.com/AI-ON/ai-on.org)

[유사 논문 검색기](http://www.arxiv-sanity.com/top)

###Daily Check
- https://twitter.com/DeepMindAI
- https://twitter.com/demishassabis
- https://twitter.com/OpenAI 
- https://twitter.com/DeepLearningHub
- https://twitter.com/jackclarksf
- https://twitter.com/karpathy
- [논문 설명]https://github.com/karpathy/paper-notes

## Deep Learning
###Algorithm
- CNN
  - GoogLe Net ( using InceptionV3 )
  - [실전 CNN ](http://www.slideshare.net/ssuser77ee21/convolutional-neural-network-in-practice)

- Recurrent Network
  - LSTM
    - [소개](https://brunch.co.kr/@chris-song/9)
  - RLU
  - E2E ( end to end Memory )
  - [generative-models](https://openai.com/blog/generative-models/)
  
###Project
- Magenta 
  - [Google Magenta(작곡 딥러닝)](https://tensorflowkorea.wordpress.com/2016/07/11/magentas-paper-reviews/)
  - [music-art-and-machine-intelligence](https://tensorflowkorea.wordpress.com/2016/07/17/music-art-and-machine-intelligence-workshop-2016/)
  
### DataSet
- [3D Human Pose DataSet](http://domedb.perception.cs.cmu.edu/dataset.html)
- [google youtube video dataSet](https://research.googleblog.com/2016/09/announcing-youtube-8m-large-and-diverse.html)
- [google image dataSet](https://tensorflowkorea.wordpress.com/2016/10/02/open-images-dataset/)
- [KAIST_Corpus](http://semanticweb.kaist.ac.kr/home/index.php/KAIST_Corpus)

###Posting
- [현대적 얼굴 인식](https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78#.m0jnipu5o)
- [Deep Learning AI Made More Rational by MIT](https://edgylabs.com/2016/11/16/deep-learning-ai-human/)
- [Urban Sound Classification](https://tensorflowkorea.wordpress.com/2016/11/06/urban-sound-classification/)
- [논문리뷰/  구글, 인공지능 기반 암호화 알고리즘 개발](http://cpuu.postype.com/post/422940/)
- [Attention and Augmented Recurrent Neural Networks](http://distill.pub/2016/augmented-rnns/?utm_content=buffer55654&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer)
- [Random synaptic feedback weights support error backpropagation for deep learning](http://www.nature.com/articles/ncomms13276)
- [deep-learning-papers-reading-roadmap]
 - [tensorflow](https://tensorflowkorea.wordpress.com/2016/10/25/deep-learning-papers-reading-roadmap/)
 - [github Page](https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap)
- [openai-infrastructure-for-deep-learning](https://openai.com/blog/infrastructure-for-deep-learning/)
- [Attention and Augmented Recurrent Neural Networks](http://distill.pub/2016/augmented-rnns/)
- [how-to-run-text-summarization-with-TF](https://medium.com/@surmenok/how-to-run-text-summarization-with-tensorflow-d4472587602d#.4cec2w7t3)
- [introduction-to-deep-learning](http://blog.algorithmia.com/introduction-to-deep-learning-2016/)
- [해커에게 전해들은 머신러닝](https://tensorflowkorea.wordpress.com/2016/10/31/%ED%95%B4%EC%BB%A4%EC%97%90%EA%B2%8C-%EC%A0%84%ED%95%B4%EB%93%A4%EC%9D%80-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/)
- [WaveNet: DeepMind’s New Model for Audio](https://tensorflowkorea.wordpress.com/2016/09/09/wavenet-deepminds-new-model-for-audio/)
- [Generating Videos with Scene Dynamics](http://web.mit.edu/vondrick/tinyvideo/)
- [Deep Learning For 이미지 분석 ](https://www.facebook.com/groups/TensorFlowKR/permalink/321214624886269/) 
- [Image Completion with Deep Learning in TensorFlow](http://bamos.github.io/2016/08/09/deep-completion/)
  - [구현](https://github.com/jazzsaxmafia/Inpainting)   
- [Face Auto Gen](https://tensorflowkorea.wordpress.com/2016/08/18/neural-facegrid-by-discgen/)
- [Google opensource new image captioning](https://tensorflowkorea.wordpress.com/2016/09/23/google-opensource-new-image-captioning-model-im2txt/)
- [ConvNet with WebGL](https://tensorflowkorea.wordpress.com/2016/08/18/convnet-with-webgl/)
- deeplearning2016_montreal
  - [Video](http://videolectures.net/deeplearning2016_montreal/)
- [AI 온라인 컨퍼런스](http://ai.withthebest.com/)
- [Deep Learing Book Study](https://tensorflowkorea.wordpress.com/2016/09/23/deep-learning-textbook-study-group/)
- [Machine Learning Top 10 Articles ](https://medium.mybridge.co/machine-learning-top-10-articles-for-the-past-month-2f3cb815ffed#.v5pj4aa7o)
- [Beyond Deep Learning – 3rd Generation Neural Nets](http://www.datasciencecentral.com/profiles/blogs/beyond-deep-learning-3rd-generation-neural-nets)
- facebook Object Recognation in Image 
  - [facebook posting](https://code.facebook.com/posts/561187904071636)
  - [tensorflowkorea Po](https://tensorflowkorea.wordpress.com/2016/08/26/facebook-open-source-image-recognition-tools/)
  
###tensorflow
- [distributed-tensorflow](https://tensorflowkorea.wordpress.com/2016/07/17/distributed-tensorflow-design-patterns-and-best-practices/)

###Lecture
- sung kim - https://www.youtube.com/watch?v=BS6O0zOGX4E&list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm
- CS231n: [Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/) / [Video](https://www.youtube.com/watch?v=NfnWJUyUJYU&list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC) /[강의 노트 한글](http://ishuca.tistory.com/category/CS231n)
- Kmooc :
  - 경영데이터 마이닝 : http://www.kmooc.kr/courses/course-v1:HYUk+HYUBUS3099k+2016_C1/info
  - 인공지능과 기계학습 : http://www.kmooc.kr/courses/course-v1:KAISTk+KCS470+2015_K0201/info
- [Deep Generative Models](https://portal.klewel.com/watch/webcast/deep-learning-tools-and-methods-workshop/talk/6)
- [ICML’15](http://dpkingma.com/?page_id=483)
- [Google I/O Extended Seoul 2016 - Tensorflow 101](https://www.youtube.com/watch?v=7UwAz4Jvvko)
- [Deep Learning for Computer Vision Barcelona 2016 ](http://imatge-upc.github.io/telecombcn-2016-dlcv/)
- [코세라 NLP](https://www.coursera.org/learn/natural-language-processing)
- [아카데믹 토렌트](http://academictorrents.com/)
- [
creative-applications-of-deep-learning-with-TF](https://www.kadenze.com/courses/creative-applications-of-deep-learning-with-tensorflow/info)
- EXEM Seminar
  - [뇌과학으로 본 인공지능의 현주소와 미래 01](https://www.youtube.com/watch?v=efWSbITntR0)
  - [EXEM Seminar / 뇌과학으로 본 인공지능의 현주소와 미래 ](https://www.youtube.com/watch?v=48EsevSvoRw)

 
###Papers
 - [QUASI-RECURRENT NEURAL NETWORKS]
   - [paper](https://arxiv.org/pdf/1611.01576v1.pdf)
   - [영어설명](http://metamind.io/research/new-neural-network-building-block-allows-faster-and-more-accurate-text-understanding/)
- [Deepmind-Neural Machine Translation in Linear Time](https://arxiv.org/pdf/1610.10099v1.pdf)
 - WaveNet architecture를 응용하여 구현한 것으로, 두 개의 dilated conv stack을 묶어서 linear time translation을 구현하였습니다. 응용 범위가 상당히 많을 것 같네요. sequence to sequence linear time transformation filter가 필요한 경우에 적용하면 잘 될 것 같습니다.
예를 들어, deep professional singer(일반인의 노래를 가수처럼 바꿔주는 conditional network) 같은 것도 가능할 것 같고요. :)
기존의 RNN approach보다 "긴 시간"의 정보를 손실 없이 잘 capture해 낼 수 있기에, 시계열 정보 분석에서도 탁월한 성능을 내지 않을까 추측해 봅니다
- [fast-weights-rnn](https://tensorflowkorea.wordpress.com/2016/10/25/fast-weights-rnn/)
- [Deep Feature Interpolation for Image Content Changes](https://arxiv.org/abs/1611.05507)
- [PVANET: Deep but Lightweight Neural Networks for Real-time Object Detection](https://arxiv.org/abs/1608.08021)
  - [imp](https://github.com/sanghoon/pva-faster-rcnn)
  - 오늘 AI Korea에 PVANET 논문이 소개되었습니다. 예전에 재밋게 읽었던 논문이고, 1저자이신 김계현 (Kim Kye-Hyeon)님은 Intel Korea에서 현재는 SK T-Brain에 계신 것으로 알고 있습니다. (역시 고급 인력들이 많이 계시는 SK T-Brain이네요. )
이 논문을 읽으시면서 참고하실 만한 논문을 소개시켜드릴까 합니다. 좀 오래된 논문인데, Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units (https://arxiv.org/abs/1603.05201, ICML 2016) 입니다. 유명하신 이홍락 교수님 그룹에서 나온 논문입니다. 이 논문의 핵심 아이디어는 Concatenated rectified linear unit인데, 간단히 설명드리면, conv_1 ~ 3 정도 아래 conv_layer에서 conv_layer의 값을 negate하고, 원래 값과 그 값을 연결하여 ReLU로 보낸다입니다.
이 말이 무슨 말이냐면.. 논문의 그림에서 확인하실 수 있겠지만, AlexNet과 같은 네트웍의 낮은 레이어 (conv_1~3)정도의 filter들이 서로 opposite한 filter들이 많이 존재한다는 것을 관찰하였습니다. 그래서 그런 opposite한 filter를 학습 및 계산해주는 대신 filter의 activation 값을 negation해 주고 concatenate 시켜서 넘긴다는 아이디어입니다. 그닥 많은 연산이 필요없는 negation 연산을 통해 학습이 많은 opposite한 filter들을 학습할 필요도 없고 계산할 필요도 없어집니다.
PVANET의 디자인에서 가장 눈에 띄는 건 이 Concatenated rectified linear unit와 1x1 convolution 등을 이용하여 Inception 개념을 적용한 거라고 보입니다.
아.. 얘기를 시작한 김에.. 이홍락 교수님 논문에서 발견한 특징은 낮은 레이어의 conv layer의 filter들이 서로 opposite한 경향이 크다는 것이였습니다. 그런데, 최근 Doubly Convolutional Neural Networks (NIPS 2016, https://arxiv.org/abs/1610.09716) 논문에서는 서로 translation을 하였을 경우의 correlation이 상당히 높은 filter들이 많이 존재한다는 것을 관찰하고 그 특성을 이용할 수 있는 방식으로 Double Convolution이라는 개념을 적용하여 논문을 제출하였습니다. 또한 최근 ASP Vision: Optically Computing the First Layer of Convolutional Neural Networks using Angle Sensitive Pixels (https://arxiv.org/abs/1605.03621v3)란 논문을 읽어보면 각 filter들의 Angle에 대한 논의도 보실 수 있을거 같습니다.
아무튼 -_- 논문이 소개된걸 다시 소개하러 왔다 헛소리만..
- [OpenAI-Improved Techniques for Training GANs](https://arxiv.org/pdf/1606.03498v1.pdf)
- [Video Pixel Networks](https://arxiv.org/pdf/1610.00527v1.pdf)
- A New Method to Visualize Deep Neural Networks( Deep NN  시각화 ) -  http://arxiv.org/abs/1603.02518v2
- Deep Speech 2(음성인식) - https://arxiv.org/abs/1512.02595
- [Bag of Tricks for Efficient Text Classification-CPU가 더 빠른.](https://arxiv.org/pdf/1607.01759v2.pdf)
- [Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding](https://arxiv.org/abs/1606.01847)
- [지워진 부분 그리기 Context Encoders: Feature Learning by Inpainting](http://people.eecs.berkeley.edu/~pathak/context_encoder/)
- [Layer Normalization](http://arxiv.org/pdf/1607.06450.pdf) - 배치 노말라이제이션을 변형하여 입력 데이터의 평균과 분산을 이용해 레이어 노말라이제이션을 적용
  - https://tensorflowkorea.wordpress.com/2016/07/24/layer-normalization/ 
- [Matching Networks for One Shot Learning  ](https://arxiv.org/pdf/1606.04080.pdf)
  - [정리](https://github.com/karpathy/paper-notes/blob/master/matching_networks.md)
- [학습과 에러전파를 따로-DeepMind Decoupled Neural Interfaces using Synthetic Gradients](https://arxiv.org/pdf/1608.05343.pdf) 
  - [summary](https://tensorflowkorea.wordpress.com/2016/08/22/decoupled-neural-interfaces-using-synthetic-gradients1608-05343-summary/) 
  - [Deep mind BLog](https://deepmind.com/blog#decoupled-neural-interfaces-using-synthetic-gradients)
  - [summary2](https://tensorflowkorea.wordpress.com/2016/08/31/synthetic-gradient-revisited/)
- [Densely Connected Convolutional Networks](http://arxiv.org/abs/1608.06993)
  - 오늘 소개시켜 드릴 논문은 "Densely Connected Convolutional Networks" (http://arxiv.org/abs/1608.06993)입니다.
일종의 residual network라고 볼 수 있을거 같습니다. 그런데 논문에 나온 그래도, "each layer is directly connected to every other layer in a feed-forward fashion" 모든 레이어가 앞에 나오는 모든 레이어와 직접 연결되어 있습니다. 그래서 이름이 Densely Connected Convolutional Networks (DenseNet) 입니다.
일단 설명만 들어도 복잡하고 파라미터가 많아질거 같습니다. 그러나 저자들은 이렇게 연결을 많이 해서 생기는 장점때문에 오히려 적은 레이어가 필요하여 생각하는 만큼 오버헤드도 크지 않고 오히려 효율적이라고 하고 있습니다. 그 중 가장 중점이 되는 주장은 skip-connection으로 모든 레이어에 연결되어 있어 feature의 재상용이 증가하고, 그럼으로 파라미터가 줄어든다고 합니다.
음.. 저자들의 일방적인 주장같지만 어쩌면 일리가 있습니다. Residual Networks are Exponential Ensembles of Relatively Shallow Networks(https://arxiv.org/abs/1605.06431)에 보면 어려운 task를 할 때 resinet을 이루는 Shallow Networks들의 길이가 더 길어지고 쉬운 일을 할 때 좀 짧아진다고 한듯...(기억이 가물..가물) 합니다. 그렇다면 중복이나 비효율성이 있을거고 그것을 줄이는 방법으로 한듯 합니다.
이렇게 무식해 보이지만 다 연결해서 몇 public set에서는 최고 성능을 찍었습니다. 그러고 보니 최근 이런 식의 skip connection을 늘리는 연구가 많이 진행 되었습니다.
    - AdaNet: Adaptive Structural Learning of Artificial Neural Networks (https://arxiv.org/pdf/1607.01097v1.pdf)
    - Collaborative Layer-wise Discriminative Learning in Deep Neural Networks (https://arxiv.org/pdf/1607.05440v1.pdf)
AdaNet이나 Collaborative Layer-wise Discriminative Learning 같은 경우는 skip connection을 상황에 맞게 늘리는 것으로 이해했습니다. (물론 제가 맞는지 저도 모른다는거..) 비교할만한 성능이 제시 안 되어 있어 비교는 힘들지만, deep learning이라는 점에서 무식해 보이는 densenet이 오히려 좋을 수 있을거라는 생각이 듭니다. 학습 과정에서 또 알아서 최적화를 해 버릴 수 있다는 이상한 예감이....
 
###구현 
- deep-learning-for-chatbots : http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/
- [Caption Gen, slide Shaer](http://www.slideshare.net/ssuser06e0c5/a-neural-image-caption-generator)
- [Papers implemented By Tensorflow](https://github.com/LeavesBreathe/tensorflow_with_latest_papers)
- [fast waveNet 구현](https://github.com/tomlepaine/fast-wavenet)




